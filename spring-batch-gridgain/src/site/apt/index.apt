* Summary

  * Samples all work out of the box as listed.  

  * Hadoop is very command-line oriented, so at first everything looks like a static method.  Indeed there may be some problems there (<<<JobClient.setCommandLineConfig>>> looks like a hack), but it seems possible in principle to run from a custom Java wrapper.

  * There are outstanding issues with embedded usage (as opposed to command line).

* Questions and Comments

  * Looks like <<<DistributedCache>>> might not work in a heterogeneous cluster because it uses <<<System.getProperty("path.separator")>>>.

  * The whole Map-Reduce thing might never work in OSGi because of heavy use of <<<Class.forName>>> and <<<Thread.setContextClassLoader>>>.  Maybe that's OK for the remote tasks - Hadoop runs it's own little cluster of Jetty servers, so it's best to just stay out of that - but it probably makes it impossible to embed the launcher in an OSGi application.

* Implementation Notes

  * Debug options:

+---
HADOOP_OPTS="-Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000 -Xdebug" 
+---

  * Running from a custom Java main is harder than it needs to be.  Can't work out how to add stuff to the classpath.  Works with -libjars on the command line (N.B. only for <<<hadoop jar>>>, not for <<<hadoop MyClass>>>).

  * N.B. twitchy command line for -libjars (pay careful attention to order).  This works:

+---
HADOOP_CLASSPATH=target/classes/ /c/Programs/hadoop-0.17.1/bin/hadoop jar -libjars target/hello.hadoop-1.0.0.CI-SNAPSHOT.jar target/foo.jar hello.hadoop.App
+---

  (The <<<App>>> class and the mapper/reducer are all defined in hello.hadoop*.jar.  The other jar is a dummy to get the command line working.)
